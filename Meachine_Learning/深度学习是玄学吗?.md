##  如何看待深度学习是玄学的论调？


最近在整理以前学习过的机器学习，深度学习，视觉定位和导航， 计算机视觉几个学科的时候，发现了一些有趣的联系。 逛知乎的时候偶然发现了一个论述，说
机器学习是统计，而深度学习已经脱离了统计，陷入了玄学的范畴。 这个好像也是周围很多人的观点。 我自己思考了一下这个问题，下文是我的思考。

机器学习(特指目前主流的统计机器学习)的有参数模型（暂时不讨论无参数模型和非统计的机器学习），本质上还是用统计方法进行参数估计。深度学习用神经网络模拟超级复杂的函数，普通的机器学习比如线性回归模型是在给定普通函数然后去估计函数的参数，
假定普通函数的结果服从某种分布，而这种分布对应的模型我们称为广义线性模型（GLM），回归中这种GLM对应分布就是指数族分布，比如线性回归中的高斯分布对应的分布函数，逻辑回归中的二项分布对应的分布函数 p = 1/(1+e^ax),都是指数族分布的特例。觉得玄是因为要模拟的高维空间的函数超级复杂，参数的意义不明确，但其实本质上
和y=ax的a是什么意义，我们也是不好讲的，高维空间的复杂函数的高维多了x平方，三次方等高维特征，我们觉得y=ax好理解，是因为习以为常，见怪不怪，而不是因为我们真的理解a是什么意义，这就要上升到哲学高度去讨论了。

另一方面，深度学习所解决的目标，他不同于机器学习的广义线性模型，他的概率分布一般也是无法显示给出，其实本质上是用到一种我们称为递归广义非线性模型，即分层的广义的非线性的递归的函数去模拟各种种分布，现实世界中复杂问题的复杂，就复杂在其正确答案的分布是无法用简单线性模型的概率分布去模拟的，
而深度学习通过计算一种复杂参数去模拟了这种真实世界的复杂概率分布,具体如何模拟去看下文给的链接，主要从理解什么是广义的，什么叫非线性，什么叫递归三个点着手。如果非要讲理解这样的玄学，那请你先理解人脑处理复杂问题的逻辑。事实上我们暂时是无法理解的，
其实我们也不需要理解，我们处理现实问题就是一种见多了就知道怎么去处理问题的，这就是所谓的社会经验，这就是个训练的过程，这个训练的过程就是一个统计的过程，
而不是一个因果关系推导的过程。进而理解这个问题的本质是对统计数学的理解，而不是玄学。不理解深度学习的作用原理的人，其实说的是不理解统计数学。人们总喜欢把自己不理解的东西成为玄学。就好比我们小时候觉得世界好奇妙，那时候我们什么都不知道，所有的东西都很玄，但我们通过不断的学习，去记忆前人总结的规律定理，获得了很多先验知识时候，从而试图用他们的框架去理解世界的时候，我们发现好像确实这个世界有章可循，我们自以为我们理解了这个世界，然后因果律产生了。

但是，当我们妄图通过简单的因果律去理解世界时，我们会发现很多事情不可理解，这就是个哲学问题，这个世界本质是不可理解的(好吧，是否可以理解就要要辩论唯物主义唯心主义不可知论了，这个存而不论)，只是我们看多了觉得某件事情就应该是这样，
这就产生了因果律(关键哲学家休谟)。引用一下休谟的人性论---“我们无从得知因果之间的关系，只能得知某些事物总是会连结在一起，而这些事物在过去的经验里又是从不曾分开过的。我们并不能看透连结这些事物背后的理性为何，我们只能观察到这些事物的本身，并且发现这些事物总是透过一种经常的连结而被我们在想像中归类。”（Hume, 1740: 93）。就像在《西方美学》一书中，詹姆逊分析了阿尔杜塞为代表的结构主义马克思主义对传统马克思主义的批判，批判传统的马克思主义的缺陷在与其
机械因果律和表现性因果律。分析中说，机械因果律在文化分析中仍然存在局部合法性，因为他仍然是我们这个特别堕落的现实社会的现实法则之一，与此同时，
表现性因果律也是我们的历史现实内部的局部法则之一。社会科学领域的得到的结论与我们数学领域得到的结论多么的相似。我们总是会陷入某种局部极值，
但很多问题中这种局部极值却是堪用的，这就是为什么机器学习中为什么总是能够给一些很强的假设，去推导(因果链)出一个结论，这个结论本质上由于假设不成立，
就应该是错的，但事实告诉我们这个结论是堪用的。但为什么这个错误的结论却是堪用的呢？这个问题在往后问就是是哲学问题进而演变成了所谓的玄学。
我们都知道我们不能总是去问为什么，因为迟早有一个为什么所有人都答不出来，我们看似严丝合缝的因果推理都建立在一些不能讲为什么的公理上的。
如果这就是玄学，那么所有的数学公理都是具有玄学性的。但在现实生活中我们不去思考为什么，思考为什么是在帮助我们解决怎么干的问题(在中国广泛影响的工具论，这种逻辑也阻碍了中国近代科学的进步)。对于普通人而言，
大部分情况下思考本身不是目的，而是手段。所以当我们去思考深度学习本身的时候，我们不是为了思考他而思考他，而是为了用它解决局部问题。
当我们把所有用因果律思考不了的问题都乘之为玄学，本省就是个逻辑怪圈。因为所有的问题都是基于一些玄学性的不可理解的假设而推导出来的，
但所有问题是不是都可以称之为玄学问题。有人说现代科学的基础是可以证伪，这来源于波普尔对科学实在性的定义，这个定义本身在科学哲学界也饱受批判。
我们姑且假设这个标准成立，是真理(其实不是)。那么如何去理解数学的不可真伪即不科学性？其实这个问题问错了，这是一个数学实在论的问题。
因为我们对科学的“科学性”的判断是往往是基于a是否基于经验的或者实证的证据b是否具有定量特征。 所以问数学是否科学（而不是玄学)，就好像是在问，
哺乳动物是猴子吗？问题就问错了。

我们再回过头来看数学领域具体的问题。复杂问题如果可以通过简单因果逻辑理解，那就不是复杂问题，而是简单问题，可以逻辑推导（因果律）。
而深度学习的起因是模拟人脑的神经元去做复杂问题的求解，所以具体化逻辑上看不懂才是深度学习固有属性，如果我们看懂了，其实就已经不需要深度学习了，就不需要统计了。
但跳出具像化的逻辑，从抽象化的角度来看，这件事本质还是个用统计方法去做参数估计的过程，这里的参数就是神经元之间的连接线，激活函数帮助我们把连接线之间
的线性关系转换成非线性关系，所以我们才能模拟非线性函数进而去模拟这个世界，对于具体问题用什么非线性函数呢，就是涉及到参数化和数学建模的问题。而参数的更新用梯度下降，是因为复杂函数，无法使用解析解。何为解析解？在线性回归中，我们理论上是可以公式推理，
用线性代数，通过SVD分解去算样本的伪逆而解出超定方程的结果，但当样本过大时，SVD时矩阵逆运算时间复杂度是O(n^3)的，计算量超级大，我们想要绕过这个时间复杂度，
所以我们选用了梯度下降去更新参数，当参数更新值不大时，我们称之为收敛，就求出了参数（参数估计)，也即求出了从输入x到输出y的映射，这个过程是个定量化求解
的过程，也是基于实证的，符合我们上文对科学的理解。而线性回归的函数恰好是一个凸函数，局部极恰好值就是全局最值(运气好)，这还是一种可以理解的简单函数，
而深度学习或者深度学习有时候work有时候不work, 也是因为梯度下降本身不能求全局极值，或者就是因为样本不够，无法覆盖全局函数，也就无法估计全局函数的参数，
就好比你让一个还没有看过社会复杂人心险恶的儿童，去面对处理成人社会的复杂问题，本来就是不可行的教育逻辑(训练逻辑)。所以我们说机器学习为什么叫学习，
为什么叫机器，这个机器的本质就是对于客观世界抽象化（参数化）得来的参数，学习的方法的本质就是统计，所以我问首说统计机器学习的参数化模型的本质就是用统计方法去做参数估计。
而深度学习是其字迹的子集所以还是具有统计特性的。

所以当有人说深度学习脱离统计，陷入玄学，一是统计的理解还不够深入，二是对于统计学 数学 科学之间的关系没搞明白。


说口说一句，我参数估计更新方法(非线性优化问题)的重要方法包括了一阶梯度下降(最速下降法)，二阶梯度下降(牛顿法，二阶泰勒展开)，高斯牛顿法， 列文伯格-马儿夸特算法。这几个方法的前提是对目标函数的能够求导(高等数学上)。深入理解还要去看数值优化的书籍。而SLAM里面常用的的Ceres的数值优化库，帮我们解决了复杂函数的自动求导的问题，所以CS下搞SLAM的人可以不用注意数值优化的具体解法，直接掉用库函数就可以解决自动求导问题，要注意的是如何构建目标函数(通常是一个最小二乘函数)，所以搞SLAM的人是在思考如何对具体问题建模的问题，模型建好后，调用库自动求导就好。

## Future work

我们会发现一个SLAM和深度学习的相似性，都有自动求导机制。深度学习框架(caffe,pytorch,tensorflow,Mxnet)里面的自动求导, 到底跟Ceres里面的自动求导有什么不同？我们是否可以用Ceres去做深度学习，或者用深度学习去替代Ceres去做SLAM里面的参数更新问题？这两个问题笔者还没思考出逻辑自洽的答案。 下面给一些小思考。

深度学习框架下，用的链式求导法则，都只用了一阶梯度，也就用了一阶泰勒展开，然后逐层递归，是一种简单数学逻辑的复用，因为神经网络中每个神经元和及其连接(线性方程)，包括激活函数(易于求导的非线性连接函数)其实本质上还是简单的数学逻辑，对他们的求导并不复杂。框架解决的一个主要问题是数值计算（求导），以及网络的基本组成单元的计算。所以我们称之为深度学习框架而不是自动求导框架。

深度学习炼金术士们解决的如何利用这些基本组成单元去设计复杂的网络结构，从而去模型现实生活中个各种问题。这也是一种建模，不过不能算是数学建模的，这是一种很直观的建模形式，所以我们这些炼金术士本质上都还是个工程师，而不需要成为数学家，学计算机的人不理解深度学习，其实是不理解数学，毕竟大家也就基本上过一个学期的概率和统计，研究生可能还有一个学期的数理统计，都讲一些大而化之的抽象概念，我们能做出题目过了考试就已经很艰难了，何谈去应用。而有些计算机科学写的专家去研究了统计学的知识，然后偷偷的拿过了换了个名字，在形象的实际问题上大量的应用，并发现可以取得很好的效果，然后悄悄的把统计的名词换个名字，结合上计算机的工程实现，就产生了深度学习(机器学习)。

所以深度学习现在火了是一种简单数学逻辑在工程上面的应用的成功， 是一种工具论的成功。这里数学成为了一种工具，具体来说主要是求导工具解决了深度神经网络参数求解的问题，进而用这个求出的网络，可以去解决了很重要而复杂的现实生活问题。这些问题复杂体现在因果关系的理解上的复杂，所以简单的逻辑推演是无法解决的，我们以前都是人去大量学习先验知识，做各种模拟练习，去处理这其中的复杂的相关系性，只是现在我们可以用深度神经网络去模拟这其中的复杂相关系，其实里面的数学逻辑还是简单朴素显而意见的。现在我们不用人去学习了，我们给用神经网络去模拟了人的学习过程，这个神经网络本身可以看做是一个机器，我们用简单数学逻辑赋予了不断更新自己的能力，就是我们所谓的机器学习，这也是为什么我们总是把深度学习与人工智能划等号的原因。

所以目前看来，人工智能中，人工的含义是人为的利用模型化参数化的数学方法模拟这个世界，智能的含义是能够解决现实世界的问题，从长远来看，人工智能的胜利将是数学语言去解释世界（相比于阴阳五行之类的学说解释世界）的胜利。是一种工具论的胜利。人工智能科学家核心能力是一种用数学语言表达世界的能力， 以及把数学语言翻译成程序语言的能力。

在理解力人工智能的含义和深度神经网络的原理和作用后，我们再来看Ceres,如果说深度学习管家实现并使用了简单的数学逻辑,那相比而言，Ceres要解决的是稍微复杂一点的数学逻辑的实现，比如让泰勒展开到二阶项，二阶导函数[hessian矩阵]，就是牛顿法；二阶导函数不好求的时候用什么方法去近似，就是高斯牛顿法解决的问题；高斯牛顿法二阶展开后，在多大范围内这种展开是有效的（非线性优化中的信赖区域法），就是列文伯格-马儿夸特（阻尼牛顿法）算法解决的问题。以上这些问题怎么用程序求解，就是Ceres库解决的问题，在SLAM中广泛运用。所以我们称Ceres为非线性优化库，而不是自动求导库。如何构建这样一个非线性优化问题，写出一个等待优化的函数，把各种信息融合在一起，是SLAM工程中具体要解决的问题，这很像深度学习中如何写损失函数。笔者把深度学习中的损失函数理解为SLAM中的优化函数的超集。从这个角度出发，深度学习的框架理论上或许是可以解决SLAM中的优化问题，但具体要怎么构建这个样一个优化方程（或者损失函数），是个棘手的问题，有待进一步讨论。

另一方面，SLAM里面常用的优化库还有g2o,这里面也有各种自动求导，跟Ceres有什么联系呢？基于自动求导进行数值优化，当然是不可或缺的部分，但还不够。g2o主要贡献在于针对SLAM问题，SLAM的模型建立，框定成为一个简单图论问题，用上了图论的知识去优化目标方程。所以我们称之为图优化库，即基于图论的非线性优化库。这里的理解和Ceres一样，我们当然不能成之为自动求导库。g2o的缺陷在于我们必须把问题放到图论的优非线性优化框架下建模，不如ceres这种不带图论的非线性优化库灵活多变。

本文开头，假设了我们讨论的是主流的：统计的机器学习的参数化模型，非统计的机器学习是怎么做的？为什么现在不流行了？无参数的统计机器学习模型是否以同样可以放到参数估计的框架下去理解？这个问题笔者后面会继续写文章讨论


## 致谢

感谢泰勒，感谢牛顿，感谢各种数学家们的理论研究，为我们这些工科狗造出了各种数学工具，让我们这些肉眼凡胎摆脱了对纯粹数学理论论的研究。

[从统计学角度来看深度学习](https://cosx.org/2015/05/a-statistical-view-of-deep-learning-i-recursive-glms/)
