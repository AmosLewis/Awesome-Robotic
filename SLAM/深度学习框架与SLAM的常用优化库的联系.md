## 深度学习框架与同时定位和建图(SLAM)的常用优化库的联系

建议先看我的这篇解释深度学习和机器学习的文章  [深度学习是玄学吗？](https://github.com/AmosLewis/Awesome-Robotics/blob/master/Meachine_Learning/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%98%AF%E7%8E%84%E5%AD%A6%E5%90%97%3F.md)

我们会发现一个SLAM和深度学习的相似性，都有自动求导机制。深度学习框架(caffe,pytorch,tensorflow,Mxnet)里面的自动求导, 到底跟Ceres里面的自动求导有什么不同？我们是否可以用Ceres去做深度学习，或者用深度学习去替代Ceres去做SLAM里面的参数更新问题？这两个问题笔者还没思考出逻辑自洽的答案。 下面给一些小思考。

深度学习框架下，用的链式求导法则，都只用了一阶梯度，也就用了一阶泰勒展开，然后逐层递归，是一种简单数学逻辑的复用，因为神经网络中每个神经元和及其连接(线性方程)，包括激活函数(易于求导的非线性连接函数)其实本质上还是简单的数学逻辑，对他们的求导并不复杂。框架解决的一个主要问题是数值计算（求导），以及网络的基本组成单元的计算。所以我们称之为深度学习框架而不是自动求导框架。

深度学习炼金术士们解决的如何利用这些基本组成单元去设计复杂的网络结构，从而去模型现实生活中个各种问题。这也是一种建模，不过不能算是数学建模的，这是一种很直观的建模形式，所以我们这些炼金术士本质上都还是个工程师，而不需要成为数学家，学计算机的人不理解深度学习，其实是不理解数学，毕竟大家也就基本上过一个学期的概率和统计，研究生可能还有一个学期的数理统计，都讲一些大而化之的抽象概念，我们能做出题目过了考试就已经很艰难了，何谈去应用。而有些计算机科学写的专家去研究了统计学的知识，然后偷偷的拿过了换了个名字，在形象的实际问题上大量的应用，并发现可以取得很好的效果，然后悄悄的把统计的名词换个名字，结合上计算机的工程实现，就产生了深度学习(机器学习)。

所以深度学习现在火了是一种简单数学逻辑在工程上面的应用的成功， 是一种工具论的成功。这里数学成为了一种工具，具体来说主要是求导工具解决了深度神经网络参数求解的问题，进而用这个求出的网络，可以去解决了很重要而复杂的现实生活问题。这些问题复杂体现在因果关系的理解上的复杂，所以简单的逻辑推演是无法解决的，我们以前都是人去大量学习先验知识，做各种模拟练习，去处理这其中的复杂的相关系性，只是现在我们可以用深度神经网络去模拟这其中的复杂相关系，其实里面的数学逻辑还是简单朴素显而意见的。现在我们不用人去学习了，我们给用神经网络去模拟了人的学习过程，这个神经网络本身可以看做是一个机器，我们用简单数学逻辑赋予了不断更新自己的能力，就是我们所谓的机器学习，这也是为什么我们总是把深度学习与人工智能划等号的原因。

所以目前看来，人工智能中，人工的含义是人为的利用模型化参数化的数学方法模拟这个世界，智能的含义是能够解决现实世界的问题，从长远来看，人工智能的胜利将是数学语言去解释世界（相比于阴阳五行之类的学说解释世界）的胜利。是一种工具论的胜利。人工智能科学家核心能力是一种用数学语言表达世界的能力， 以及把数学语言翻译成程序语言的能力。

在理解力人工智能的含义和深度神经网络的原理和作用后，我们再来看Ceres,如果说深度学习管家实现并使用了简单的数学逻辑,那相比而言，Ceres要解决的是稍微复杂一点的数学逻辑的实现，比如让泰勒展开到二阶项，二阶导函数[hessian矩阵]，就是牛顿法；二阶导函数不好求的时候用什么方法去近似，就是高斯牛顿法解决的问题；高斯牛顿法二阶展开后，在多大范围内这种展开是有效的（非线性优化中的信赖区域法），就是列文伯格-马儿夸特（阻尼牛顿法）算法解决的问题。以上这些问题怎么用程序求解，就是Ceres库解决的问题，在SLAM中广泛运用。所以我们称Ceres为非线性优化库，而不是自动求导库。如何构建这样一个非线性优化问题，写出一个等待优化的函数，把各种信息融合在一起，是SLAM工程中具体要解决的问题，这很像深度学习中如何写损失函数。笔者把深度学习中的损失函数理解为SLAM中的优化函数的超集。从这个角度出发，深度学习的框架理论上或许是可以解决SLAM中的优化问题，但具体要怎么构建这个样一个优化方程（或者损失函数），是个棘手的问题，有待进一步讨论。

另一方面，SLAM里面常用的优化库还有g2o,这里面也有各种自动求导，跟Ceres有什么联系呢？基于自动求导进行数值优化，当然是不可或缺的部分，但还不够。g2o主要贡献在于针对SLAM问题，SLAM的模型建立，框定成为一个简单图论问题，用上了图论的知识去优化目标方程。所以我们称之为图优化库，即基于图论的非线性优化库。这里的理解和Ceres一样，我们当然不能成之为自动求导库。g2o的缺陷在于我们必须把问题放到图论的优非线性优化框架下建模，不如ceres这种不带图论的非线性优化库灵活多变。
